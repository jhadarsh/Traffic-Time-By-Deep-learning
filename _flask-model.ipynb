{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "14fde5cf-d535-470b-a45d-2b8fb1493a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "from flask import Flask, jsonify, request\n",
    "from flask_cors import CORS  # Import CORS\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import json\n",
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3ccf3936-60d5-455c-84a6-bf969ad88d65",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n"
     ]
    }
   ],
   "source": [
    "model = tf.keras.models.load_model(\"route_prediction_ann_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "695d57fa-1b93-46a2-b814-8dfde5f4211a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the saved scalers\n",
    "scaler_X = joblib.load('scaler_X.pkl')\n",
    "scaler_y = joblib.load('scaler_y.pkl')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a9016e71-e2c8-4843-8e9f-36e8629664f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"traffic_data.json\") as f:\n",
    "    traffic_data = json.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7db55631-2bb2-4ed1-a085-8887fc69edf2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<flask_cors.extension.CORS at 0x1df7b499930>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Flask app\n",
    "app = Flask(__name__)\n",
    "CORS(app)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6d99540-c5cb-4be7-aecf-b5bf89582bf0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app '__main__'\n",
      " * Debug mode: on\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:\u001b[31m\u001b[1mWARNING: This is a development server. Do not use it in a production deployment. Use a production WSGI server instead.\u001b[0m\n",
      " * Running on http://127.0.0.1:5000\n",
      "INFO:werkzeug:\u001b[33mPress CTRL+C to quit\u001b[0m\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Feb/2025 21:32:44] \"OPTIONS /api/getPrediction?start=Connaught%20Place&dest=Karol%20Bagh HTTP/1.1\" 200 -\n",
      "C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 399ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:werkzeug:127.0.0.1 - - [03/Feb/2025 21:32:45] \"GET /api/getPrediction?start=Connaught%20Place&dest=Karol%20Bagh HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Feb/2025 21:32:58] \"OPTIONS /api/getPrediction?start=Connaught%20Place&dest=AIIMS HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Feb/2025 21:32:58] \"GET /api/getPrediction?start=Connaught%20Place&dest=AIIMS HTTP/1.1\" 200 -\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Feb/2025 21:33:07] \"OPTIONS /api/getPrediction?start=Connaught%20Place&dest=Dwarka HTTP/1.1\" 200 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\sklearn\\utils\\validation.py:2739: UserWarning: X does not have valid feature names, but MinMaxScaler was fitted with feature names\n",
      "  warnings.warn(\n",
      "INFO:werkzeug:127.0.0.1 - - [03/Feb/2025 21:33:07] \"GET /api/getPrediction?start=Connaught%20Place&dest=Dwarka HTTP/1.1\" 200 -\n"
     ]
    }
   ],
   "source": [
    "# API endpoint to get predictions\n",
    "@app.route('/api/getPrediction', methods=['GET'])\n",
    "def get_prediction():\n",
    "    # Get query parameters (starting location and destination)\n",
    "    start_loc = request.args.get('start')\n",
    "    dest_loc = request.args.get('dest')\n",
    "\n",
    "    if not start_loc or not dest_loc:\n",
    "        return jsonify({\"error\": \"Please provide both 'start' and 'dest' parameters.\"}), 400\n",
    "\n",
    "    # Check if the route exists in the traffic data\n",
    "    try:\n",
    "        route_info = traffic_data[start_loc][dest_loc]\n",
    "    except KeyError:\n",
    "        return jsonify({\"error\": \"No traffic data available for this route.\"}), 404\n",
    "    \n",
    "    # Extract features from the JSON data\n",
    "    distance = route_info[\"distance\"]\n",
    "    num_signals = route_info[\"num_signals\"]\n",
    "    vehicle_count = route_info[\"vehicle_count\"]\n",
    "    red_light_delay = route_info[\"red_light_delay\"]\n",
    "    current_pollution = route_info[\"current_pollution\"]\n",
    "\n",
    "    # Compute rush factor and pollution exposure\n",
    "    rush_factor_car = vehicle_count / 300  \n",
    "    rush_factor_bike = rush_factor_car * 0.8\n",
    "    rush_factor_cycle = 0  \n",
    "    rush_factor_bus = 0  \n",
    "    rush_factor_metro = 0.4  \n",
    "    pollution_exposure_car = current_pollution\n",
    "    pollution_exposure_bike = pollution_exposure_car * 1.2\n",
    "    pollution_exposure_cycle = pollution_exposure_car * 1.5\n",
    "    pollution_exposure_bus = pollution_exposure_car * 0.8\n",
    "    pollution_exposure_metro = pollution_exposure_car * 0.5\n",
    "\n",
    "    # Prepare input data for the model\n",
    "    input_data = np.array([[distance, num_signals, red_light_delay, vehicle_count,\n",
    "                            rush_factor_car, rush_factor_bike, rush_factor_cycle, rush_factor_bus, rush_factor_metro,\n",
    "                            pollution_exposure_car, pollution_exposure_bike, pollution_exposure_cycle,\n",
    "                            pollution_exposure_bus, pollution_exposure_metro]])\n",
    "\n",
    "    # Normalize the input data (using the scaler used during training)\n",
    "    input_scaled = scaler_X.transform(input_data)\n",
    "\n",
    "    # Make predictions with the model\n",
    "    prediction_scaled = model.predict(input_scaled)\n",
    "\n",
    "    # Reverse the normalization for the output\n",
    "    output = scaler_y.inverse_transform(prediction_scaled)\n",
    "    # Convert the output to regular float types (to avoid JSON serialization errors)\n",
    "    output_floats = output[0].tolist()  # Convert numpy array to a list of floats\n",
    "\n",
    "\n",
    "    # Prepare the result as a dictionary\n",
    "    result = {\n",
    "        \"Time_Car\": float(output_floats[0]),\n",
    "        \"Time_Bike\": float(output_floats[1]),\n",
    "        \"Time_Cycle\": float(output_floats[2]),\n",
    "        \"Time_Bus\": float(output_floats[3]),\n",
    "        \"Time_Metro\": float(output_floats[4]),\n",
    "        \"Expense_Car\": float(output_floats[5]),\n",
    "        \"Expense_Bike\": float(output_floats[6]),\n",
    "        \"Expense_Cycle\": float(output_floats[7]),\n",
    "        \"Expense_Bus\": float(output_floats[8]),\n",
    "        \"Expense_Metro\": float(output_floats[9]),\n",
    "        \"Pollution_Car\": float(output_floats[10]),\n",
    "        \"Pollution_Bike\": float(output_floats[11]),\n",
    "        \"Pollution_Cycle\": float(output_floats[12]),\n",
    "        \"Pollution_Bus\": float(output_floats[13]),\n",
    "        \"Pollution_Metro\": float(output_floats[14])\n",
    "    }\n",
    "\n",
    "    # Return the result as a JSON response\n",
    "    return jsonify(result)\n",
    "\n",
    "# Run the Flask app\n",
    "if __name__ == \"__main__\":\n",
    "    app.run(debug=True, use_reloader=False)  # use_reloader=False to avoid restarting the server during testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2432e1f1-f9c6-4e46-87b8-249f3c1ebbcc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
