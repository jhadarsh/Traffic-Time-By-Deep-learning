{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ce7d2c20-6eee-41c5-ad3e-59504c231b0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import joblib  # ✅ For saving scalers\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "22b4e617-3590-4d98-b46f-d48c87a4d6e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\adars\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 3ms/step - loss: 0.1335 - mae: 0.2899 - val_loss: 0.0457 - val_mae: 0.1643\n",
      "Epoch 2/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0382 - mae: 0.1459 - val_loss: 0.0313 - val_mae: 0.1256\n",
      "Epoch 3/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0291 - mae: 0.1196 - val_loss: 0.0285 - val_mae: 0.1156\n",
      "Epoch 4/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0269 - mae: 0.1119 - val_loss: 0.0275 - val_mae: 0.1123\n",
      "Epoch 5/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0261 - mae: 0.1091 - val_loss: 0.0270 - val_mae: 0.1111\n",
      "Epoch 6/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0257 - mae: 0.1082 - val_loss: 0.0268 - val_mae: 0.1108\n",
      "Epoch 7/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0251 - mae: 0.1070 - val_loss: 0.0266 - val_mae: 0.1099\n",
      "Epoch 8/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0252 - mae: 0.1067 - val_loss: 0.0265 - val_mae: 0.1095\n",
      "Epoch 9/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0249 - mae: 0.1060 - val_loss: 0.0263 - val_mae: 0.1090\n",
      "Epoch 10/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0253 - mae: 0.1068 - val_loss: 0.0264 - val_mae: 0.1085\n",
      "Epoch 11/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0250 - mae: 0.1056 - val_loss: 0.0261 - val_mae: 0.1085\n",
      "Epoch 12/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0248 - mae: 0.1058 - val_loss: 0.0261 - val_mae: 0.1085\n",
      "Epoch 13/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1051 - val_loss: 0.0261 - val_mae: 0.1077\n",
      "Epoch 14/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1052 - val_loss: 0.0260 - val_mae: 0.1080\n",
      "Epoch 15/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1046 - val_loss: 0.0259 - val_mae: 0.1079\n",
      "Epoch 16/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1052 - val_loss: 0.0259 - val_mae: 0.1079\n",
      "Epoch 17/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1050 - val_loss: 0.0259 - val_mae: 0.1075\n",
      "Epoch 18/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1045 - val_loss: 0.0260 - val_mae: 0.1079\n",
      "Epoch 19/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1044 - val_loss: 0.0259 - val_mae: 0.1072\n",
      "Epoch 20/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1050 - val_loss: 0.0258 - val_mae: 0.1074\n",
      "Epoch 21/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0247 - mae: 0.1044 - val_loss: 0.0260 - val_mae: 0.1077\n",
      "Epoch 22/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1042 - val_loss: 0.0259 - val_mae: 0.1077\n",
      "Epoch 23/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1040 - val_loss: 0.0259 - val_mae: 0.1080\n",
      "Epoch 24/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1036 - val_loss: 0.0258 - val_mae: 0.1075\n",
      "Epoch 25/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1031 - val_loss: 0.0259 - val_mae: 0.1078\n",
      "Epoch 26/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1048 - val_loss: 0.0258 - val_mae: 0.1069\n",
      "Epoch 27/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1038 - val_loss: 0.0259 - val_mae: 0.1079\n",
      "Epoch 28/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1046 - val_loss: 0.0257 - val_mae: 0.1075\n",
      "Epoch 29/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1046 - val_loss: 0.0258 - val_mae: 0.1073\n",
      "Epoch 30/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1039 - val_loss: 0.0258 - val_mae: 0.1075\n",
      "Epoch 31/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0250 - mae: 0.1056 - val_loss: 0.0257 - val_mae: 0.1071\n",
      "Epoch 32/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0244 - mae: 0.1045 - val_loss: 0.0257 - val_mae: 0.1071\n",
      "Epoch 33/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1031 - val_loss: 0.0258 - val_mae: 0.1073\n",
      "Epoch 34/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1042 - val_loss: 0.0260 - val_mae: 0.1075\n",
      "Epoch 35/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1042 - val_loss: 0.0258 - val_mae: 0.1074\n",
      "Epoch 36/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1037 - val_loss: 0.0257 - val_mae: 0.1075\n",
      "Epoch 37/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1043 - val_loss: 0.0258 - val_mae: 0.1073\n",
      "Epoch 38/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0240 - mae: 0.1032 - val_loss: 0.0258 - val_mae: 0.1071\n",
      "Epoch 39/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0242 - mae: 0.1036 - val_loss: 0.0257 - val_mae: 0.1071\n",
      "Epoch 40/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0245 - mae: 0.1046 - val_loss: 0.0259 - val_mae: 0.1082\n",
      "Epoch 41/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0246 - mae: 0.1049 - val_loss: 0.0257 - val_mae: 0.1069\n",
      "Epoch 42/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0244 - mae: 0.1037 - val_loss: 0.0259 - val_mae: 0.1068\n",
      "Epoch 43/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0242 - mae: 0.1033 - val_loss: 0.0258 - val_mae: 0.1082\n",
      "Epoch 44/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0242 - mae: 0.1036 - val_loss: 0.0259 - val_mae: 0.1078\n",
      "Epoch 45/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0241 - mae: 0.1032 - val_loss: 0.0259 - val_mae: 0.1072\n",
      "Epoch 46/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0241 - mae: 0.1037 - val_loss: 0.0259 - val_mae: 0.1072\n",
      "Epoch 47/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 3ms/step - loss: 0.0242 - mae: 0.1035 - val_loss: 0.0258 - val_mae: 0.1075\n",
      "Epoch 48/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0243 - mae: 0.1037 - val_loss: 0.0257 - val_mae: 0.1072\n",
      "Epoch 49/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0241 - mae: 0.1032 - val_loss: 0.0258 - val_mae: 0.1070\n",
      "Epoch 50/50\n",
      "\u001b[1m267/267\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 2ms/step - loss: 0.0239 - mae: 0.1029 - val_loss: 0.0257 - val_mae: 0.1072\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 2ms/step - loss: 0.0260 - mae: 0.1078 \n",
      "Test Loss: 0.025742432102560997, Test MAE: 0.10718802362680435\n",
      "\u001b[1m32/32\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 3ms/step \n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R² Score: 0.4834\n"
     ]
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv(\"delhi_travel_data.csv\")\n",
    "\n",
    "# Features (input variables)\n",
    "X = df[[\"Distance_KM\", \"Num_Signals\", \"Total_Signal_Wait\", \"Queue_Length\",\n",
    "        \"Rush_Car\", \"Rush_Bike\", \"Rush_Cycle\", \"Rush_Bus\", \"Rush_Metro\",\n",
    "        \"Pollution_Exposure_Car\", \"Pollution_Exposure_Bike\", \"Pollution_Exposure_Cycle\",\n",
    "        \"Pollution_Exposure_Bus\", \"Pollution_Exposure_Metro\"]]\n",
    "\n",
    "# Targets (output variables)\n",
    "y = df[[\"Time_Car\", \"Time_Bike\", \"Time_Cycle\", \"Time_Bus\", \"Time_Metro\",\n",
    "        \"Expense_Car\", \"Expense_Bike\", \"Expense_Cycle\", \"Expense_Bus\", \"Expense_Metro\",\n",
    "        \"Pollution_Car\", \"Pollution_Bike\", \"Pollution_Cycle\", \"Pollution_Bus\", \"Pollution_Metro\"]]\n",
    "\n",
    "# ✅ Normalize features & target values\n",
    "scaler_X = MinMaxScaler()\n",
    "scaler_y = MinMaxScaler()\n",
    "X_scaled = scaler_X.fit_transform(X)\n",
    "y_scaled = scaler_y.fit_transform(y)\n",
    "\n",
    "# ✅ Save the fitted scalers for later use in prediction\n",
    "joblib.dump(scaler_X, \"scaler_X.pkl\")\n",
    "joblib.dump(scaler_y, \"scaler_y.pkl\")\n",
    "\n",
    "# Split data into train (80%) and test (20%) sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y_scaled, test_size=0.2, random_state=42)\n",
    "\n",
    "# Build ANN model\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(128, activation='relu', input_shape=(X_train.shape[1],)),\n",
    "    tf.keras.layers.Dense(64, activation='relu'),\n",
    "    tf.keras.layers.Dense(32, activation='relu'),\n",
    "    tf.keras.layers.Dense(y_train.shape[1], activation='linear')  # Output layer (multi-output regression)\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001),loss=tf.keras.losses.MeanSquaredError(), metrics=['mae'])\n",
    "\n",
    "# Train model\n",
    "history = model.fit(X_train, y_train, epochs=50, batch_size=15, validation_data=(X_test, y_test))\n",
    "\n",
    "# Evaluate model\n",
    "loss, mae = model.evaluate(X_test, y_test)\n",
    "print(f\"Test Loss: {loss}, Test MAE: {mae}\")\n",
    "# Make Predictions\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Compute R² Score\n",
    "r2 = r2_score(y_test, y_pred)\n",
    "\n",
    "print(f\"R² Score: {r2:.4f}\")  # Closer to 1 means better performance\n",
    "\n",
    "# ✅ Save trained model\n",
    "model.save(\"route_prediction_ann_v2.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a43dff-bbca-4335-9fb5-0b356d30866a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
